{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x1,x2,w1,w2,b1):\n",
    "    return 1/(1 + np.exp(-(x1*w1+x2*w2+b1)))\n",
    "\n",
    "def relu(x1,x2,w1,w2,b1):\n",
    "    x=x1*w1+x2*w2+b1\n",
    "    return [x if x>=0 else 0][0]\n",
    "\n",
    "def derivativeRelu(x1,x2,w1,w2,b1):\n",
    "    if relu(x1,x2,w1,w2,b1)==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def NeuralNetworkSigmoid(x1,x2,w1,w2,w3,w4,b1,w5,w6,w7,w8,b2,o1,o2):\n",
    "    h1=sigmoid(x1,x2,w1,w2,b1)\n",
    "    h2=sigmoid(x1,x2,w3,w4,b1)\n",
    "    previousError=np.inf\n",
    "    learningRate=0.1\n",
    "    Error=((sigmoid(h1,h2,w5,w6,b2)-o1)**2+(sigmoid(h1,h2,w7,w8,b2)-o2)**2)/2\n",
    "    iteration=0\n",
    "    while previousError-Error>=0.0001:\n",
    "        iteration=iteration+1\n",
    "        previousWeights=[w1,w2,w3,w4,w5,w6,w7,w8]\n",
    "        previousBias=[b1,b2]\n",
    "        commondeltaw56=sigmoid(h1,h2,w5,w6,b2)*(1-sigmoid(h1,h2,w5,w6,b2))*(sigmoid(h1,h2,w5,w6,b2)-o1)\n",
    "        commondeltaw78=sigmoid(h1,h2,w7,w8,b2)*(1-sigmoid(h1,h2,w7,w8,b2))*(sigmoid(h1,h2,w7,w8,b2)-o2)    \n",
    "        deltaw5=h1*commondeltaw56\n",
    "        deltaw6=h2*commondeltaw56\n",
    "        deltaw7=h1*commondeltaw78\n",
    "        deltaw8=h2*commondeltaw78\n",
    "        deltab2=commondeltaw56+commondeltaw78\n",
    "        w5=w5-learningRate*deltaw5\n",
    "        w6=w6-learningRate*deltaw6\n",
    "        w7=w7-learningRate*deltaw7\n",
    "        w8=w8-learningRate*deltaw8\n",
    "        b2=b2-learningRate*deltab2\n",
    "        commondeltaw56=sigmoid(h1,h2,w5,w6,b2)*(1-sigmoid(h1,h2,w5,w6,b2))*(sigmoid(h1,h2,w5,w6,b2)-o1)\n",
    "        commondeltaw78=sigmoid(h1,h2,w7,w8,b2)*(1-sigmoid(h1,h2,w7,w8,b2))*(sigmoid(h1,h2,w7,w8,b2)-o2) \n",
    "        commondeltaw12=sigmoid(x1,x2,w1,w2,b1)*(1-sigmoid(x1,x2,w1,w2,b1))*(w5*commondeltaw56+w7*commondeltaw78)\n",
    "        commondeltaw34=sigmoid(x1,x2,w3,w4,b1)*(1-sigmoid(x1,x2,w3,w4,b1))*(w6*commondeltaw56+w8*commondeltaw78)\n",
    "        deltaw5=h1*commondeltaw56\n",
    "        deltaw6=h2*commondeltaw56\n",
    "        deltaw7=h1*commondeltaw78\n",
    "        deltaw8=h2*commondeltaw78\n",
    "        deltaw1=x1*commondeltaw12\n",
    "        deltaw2=x2*commondeltaw12\n",
    "        deltaw3=x1*commondeltaw34\n",
    "        deltaw4=x2*commondeltaw34\n",
    "        a1=commondeltaw56*(w5*sigmoid(x1,x2,w1,w2,b1)*(1-sigmoid(x1,x2,w1,w2,b1))+w6*sigmoid(x1,x2,w3,w4,b1)*(1-sigmoid(x1,x2,w3,w4,b1)))\n",
    "        a2=commondeltaw78*(w7*sigmoid(x1,x2,w1,w2,b1)*(1-sigmoid(x1,x2,w1,w2,b1))+w8*sigmoid(x1,x2,w3,w4,b1)*(1-sigmoid(x1,x2,w3,w4,b1)))\n",
    "        deltab1=a1+a2\n",
    "        w1=w1-learningRate*deltaw1\n",
    "        w2=w2-learningRate*deltaw2\n",
    "        w3=w3-learningRate*deltaw3\n",
    "        w4=w4-learningRate*deltaw4\n",
    "        b1=b1-learningRate*deltab1\n",
    "        print(\"The previous Error is \"+str(previousError)+\" and the current error is \"+str(Error)+\" on iteration \"+str(iteration))\n",
    "        previousError=Error\n",
    "        h1=sigmoid(x1,x2,w1,w2,b1)\n",
    "        h2=sigmoid(x1,x2,w3,w4,b1)\n",
    "        Error=((sigmoid(h1,h2,w5,w6,b2)-o1)**2+(sigmoid(h1,h2,w7,w8,b2)-o2)**2)/2\n",
    "    print(\"The Weights and Biases after running the neural network for the activation function sigmoid are as follows:\")\n",
    "    print(\"Weights are\"+str(previousWeights))\n",
    "    print(\"Biases are \"+str(previousBias))\n",
    "    \n",
    "def NeuralNetworkRelu(x1,x2,w1,w2,w3,w4,b1,w5,w6,w7,w8,b2,o1,o2):\n",
    "    h1=relu(x1,x2,w1,w2,b1)\n",
    "    h2=relu(x1,x2,w3,w4,b1)\n",
    "    previousError=np.inf\n",
    "    learningRate=0.1\n",
    "    Error=((relu(h1,h2,w5,w6,b2)-o1)**2+(relu(h1,h2,w7,w8,b2)-o2)**2)/2\n",
    "    iteration=0\n",
    "    while previousError-Error>=0.001:\n",
    "        iteration=iteration+1\n",
    "        previousWeights=[w1,w2,w3,w4,w5,w6,w7,w8]\n",
    "        previousBias=[b1,b2]\n",
    "        commondeltaw56=derivativeRelu(h1,h2,w5,w6,b2)*(relu(h1,h2,w5,w6,b2)-o1)\n",
    "        commondeltaw78=derivativeRelu(h1,h2,w7,w8,b2)*(relu(h1,h2,w7,w8,b2)-o2)    \n",
    "        deltaw5=h1*commondeltaw56\n",
    "        deltaw6=h2*commondeltaw56\n",
    "        deltaw7=h1*commondeltaw78\n",
    "        deltaw8=h2*commondeltaw78\n",
    "        deltab2=commondeltaw56+commondeltaw78\n",
    "        w5=w5-learningRate*deltaw5\n",
    "        w6=w6-learningRate*deltaw6\n",
    "        w7=w7-learningRate*deltaw7\n",
    "        w8=w8-learningRate*deltaw8\n",
    "        b2=b2-learningRate*deltab2\n",
    "        commondeltaw56=derivativeRelu(h1,h2,w5,w6,b2)*(relu(h1,h2,w5,w6,b2)-o1)\n",
    "        commondeltaw78=derivativeRelu(h1,h2,w7,w8,b2)*(relu(h1,h2,w7,w8,b2)-o2)    \n",
    "        commondeltaw12=derivativeRelu(x1,x2,w1,w2,b1)*(w5*commondeltaw56+w7*commondeltaw78)\n",
    "        commondeltaw34=derivativeRelu(x1,x2,w3,w4,b1)*(w6*commondeltaw56+w8*commondeltaw78)\n",
    "        deltaw5=h1*commondeltaw56\n",
    "        deltaw6=h2*commondeltaw56\n",
    "        deltaw7=h1*commondeltaw78\n",
    "        deltaw8=h2*commondeltaw78\n",
    "        deltaw1=x1*commondeltaw12\n",
    "        deltaw2=x2*commondeltaw12\n",
    "        deltaw3=x1*commondeltaw34\n",
    "        deltaw4=x2*commondeltaw34\n",
    "        a1=commondeltaw56*(w5*derivativeRelu(x1,x2,w1,w2,b1)+w6*derivativeRelu(x1,x2,w3,w4,b1))\n",
    "        a2=commondeltaw78*(w7*derivativeRelu(x1,x2,w1,w2,b1)+w8*derivativeRelu(x1,x2,w3,w4,b1))\n",
    "        deltab1=a1+a2\n",
    "        w1=w1-learningRate*deltaw1\n",
    "        w2=w2-learningRate*deltaw2\n",
    "        w3=w3-learningRate*deltaw3\n",
    "        w4=w4-learningRate*deltaw4\n",
    "        b1=b1-learningRate*deltab1\n",
    "        print(\"The previous Error is \"+str(previousError)+\" and the current error is \"+str(Error)+\" on iteration \"+str(iteration))\n",
    "        previousError=Error\n",
    "        h1=relu(x1,x2,w1,w2,b1)\n",
    "        h2=relu(x1,x2,w3,w4,b1)\n",
    "        Error=((relu(h1,h2,w5,w6,b2)-o1)**2+(relu(h1,h2,w7,w8,b2)-o2)**2)/2\n",
    "    print(\"The Weights and Biases after running the neural network for the activation function sigmoid are as follows:\")\n",
    "    print(\"Weights are\"+str(previousWeights))\n",
    "    print(\"Biases are \"+str(previousBias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=0.05\n",
    "x2=0.1\n",
    "w1=0.15\n",
    "w2=0.2\n",
    "w3=0.25\n",
    "w4=0.3\n",
    "b1=0.35\n",
    "w5=0.4\n",
    "w6=0.45\n",
    "w7=0.5\n",
    "w8=0.55\n",
    "b2=0.6\n",
    "o1=0.01\n",
    "o2=0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The previous Error is inf and the current error is 0.2983711087600027 on iteration 1\n",
      "The previous Error is 0.2983711087600027 and the current error is 0.2958631594423565 on iteration 2\n",
      "The previous Error is 0.2958631594423565 and the current error is 0.2933382673887452 on iteration 3\n",
      "The previous Error is 0.2933382673887452 and the current error is 0.2907974509544987 on iteration 4\n",
      "The previous Error is 0.2907974509544987 and the current error is 0.28824176919489797 on iteration 5\n",
      "The previous Error is 0.28824176919489797 and the current error is 0.2856723199212805 on iteration 6\n",
      "The previous Error is 0.2856723199212805 and the current error is 0.2830902375178188 on iteration 7\n",
      "The previous Error is 0.2830902375178188 and the current error is 0.2804966905243903 on iteration 8\n",
      "The previous Error is 0.2804966905243903 and the current error is 0.2778928789933739 on iteration 9\n",
      "The previous Error is 0.2778928789933739 and the current error is 0.27528003163065073 on iteration 10\n",
      "The previous Error is 0.27528003163065073 and the current error is 0.2726594027335209 on iteration 11\n",
      "The previous Error is 0.2726594027335209 and the current error is 0.27003226894063737 on iteration 12\n",
      "The previous Error is 0.27003226894063737 and the current error is 0.2673999258113478 on iteration 13\n",
      "The previous Error is 0.2673999258113478 and the current error is 0.2647636842540109 on iteration 14\n",
      "The previous Error is 0.2647636842540109 and the current error is 0.2621248668248501 on iteration 15\n",
      "The previous Error is 0.2621248668248501 and the current error is 0.2594848039207023 on iteration 16\n",
      "The previous Error is 0.2594848039207023 and the current error is 0.2568448298905672 on iteration 17\n",
      "The previous Error is 0.2568448298905672 and the current error is 0.2542062790921461 on iteration 18\n",
      "The previous Error is 0.2542062790921461 and the current error is 0.2515704819205243 on iteration 19\n",
      "The previous Error is 0.2515704819205243 and the current error is 0.2489387608368042 on iteration 20\n",
      "The previous Error is 0.2489387608368042 and the current error is 0.24631242642480344 on iteration 21\n",
      "The previous Error is 0.24631242642480344 and the current error is 0.24369277350387883 on iteration 22\n",
      "The previous Error is 0.24369277350387883 and the current error is 0.2410810773255425 on iteration 23\n",
      "The previous Error is 0.2410810773255425 and the current error is 0.2384785898807722 on iteration 24\n",
      "The previous Error is 0.2384785898807722 and the current error is 0.2358865363438245 on iteration 25\n",
      "The previous Error is 0.2358865363438245 and the current error is 0.23330611167693194 on iteration 26\n",
      "The previous Error is 0.23330611167693194 and the current error is 0.23073847741854298 on iteration 27\n",
      "The previous Error is 0.23073847741854298 and the current error is 0.22818475867576138 on iteration 28\n",
      "The previous Error is 0.22818475867576138 and the current error is 0.2256460413394104 on iteration 29\n",
      "The previous Error is 0.2256460413394104 and the current error is 0.22312336953771045 on iteration 30\n",
      "The previous Error is 0.22312336953771045 and the current error is 0.2206177433419707 on iteration 31\n",
      "The previous Error is 0.2206177433419707 and the current error is 0.21813011673499072 on iteration 32\n",
      "The previous Error is 0.21813011673499072 and the current error is 0.21566139585009925 on iteration 33\n",
      "The previous Error is 0.21566139585009925 and the current error is 0.21321243748596938 on iteration 34\n",
      "The previous Error is 0.21321243748596938 and the current error is 0.2107840478995755 on iteration 35\n",
      "The previous Error is 0.2107840478995755 and the current error is 0.20837698187696227 on iteration 36\n",
      "The previous Error is 0.20837698187696227 and the current error is 0.20599194207889082 on iteration 37\n",
      "The previous Error is 0.20599194207889082 and the current error is 0.20362957865597536 on iteration 38\n",
      "The previous Error is 0.20362957865597536 and the current error is 0.20129048912563116 on iteration 39\n",
      "The previous Error is 0.20129048912563116 and the current error is 0.1989752185010717 on iteration 40\n",
      "The previous Error is 0.1989752185010717 and the current error is 0.1966842596607175 on iteration 41\n",
      "The previous Error is 0.1966842596607175 and the current error is 0.1944180539447492 on iteration 42\n",
      "The previous Error is 0.1944180539447492 and the current error is 0.1921769919641454 on iteration 43\n",
      "The previous Error is 0.1921769919641454 and the current error is 0.18996141460640917 on iteration 44\n",
      "The previous Error is 0.18996141460640917 and the current error is 0.18777161422130265 on iteration 45\n",
      "The previous Error is 0.18777161422130265 and the current error is 0.18560783596926855 on iteration 46\n",
      "The previous Error is 0.18560783596926855 and the current error is 0.18347027931482088 on iteration 47\n",
      "The previous Error is 0.18347027931482088 and the current error is 0.18135909964701732 on iteration 48\n",
      "The previous Error is 0.18135909964701732 and the current error is 0.17927441000916758 on iteration 49\n",
      "The previous Error is 0.17927441000916758 and the current error is 0.17721628292017047 on iteration 50\n",
      "The previous Error is 0.17721628292017047 and the current error is 0.17518475227029232 on iteration 51\n",
      "The previous Error is 0.17518475227029232 and the current error is 0.17317981527476475 on iteration 52\n",
      "The previous Error is 0.17317981527476475 and the current error is 0.17120143446929637 on iteration 53\n",
      "The previous Error is 0.17120143446929637 and the current error is 0.1692495397324076 on iteration 54\n",
      "The previous Error is 0.1692495397324076 and the current error is 0.16732403032041587 on iteration 55\n",
      "The previous Error is 0.16732403032041587 and the current error is 0.1654247769018848 on iteration 56\n",
      "The previous Error is 0.1654247769018848 and the current error is 0.1635516235793894 on iteration 57\n",
      "The previous Error is 0.1635516235793894 and the current error is 0.1617043898875221 on iteration 58\n",
      "The previous Error is 0.1617043898875221 and the current error is 0.1598828727571559 on iteration 59\n",
      "The previous Error is 0.1598828727571559 and the current error is 0.15808684843706886 on iteration 60\n",
      "The previous Error is 0.15808684843706886 and the current error is 0.1563160743651168 on iteration 61\n",
      "The previous Error is 0.1563160743651168 and the current error is 0.15457029098219155 on iteration 62\n",
      "The previous Error is 0.15457029098219155 and the current error is 0.15284922348322444 on iteration 63\n",
      "The previous Error is 0.15284922348322444 and the current error is 0.1511525835004681 on iteration 64\n",
      "The previous Error is 0.1511525835004681 and the current error is 0.14948007071521663 on iteration 65\n",
      "The previous Error is 0.14948007071521663 and the current error is 0.14783137439499286 on iteration 66\n",
      "The previous Error is 0.14783137439499286 and the current error is 0.14620617485404175 on iteration 67\n",
      "The previous Error is 0.14620617485404175 and the current error is 0.1446041448357147 on iteration 68\n",
      "The previous Error is 0.1446041448357147 and the current error is 0.14302495081601516 on iteration 69\n",
      "The previous Error is 0.14302495081601516 and the current error is 0.14146825422819242 on iteration 70\n",
      "The previous Error is 0.14146825422819242 and the current error is 0.13993371260882725 on iteration 71\n",
      "The previous Error is 0.13993371260882725 and the current error is 0.13842098066634487 on iteration 72\n",
      "The previous Error is 0.13842098066634487 and the current error is 0.13692971127332443 on iteration 73\n",
      "The previous Error is 0.13692971127332443 and the current error is 0.13545955638434568 on iteration 74\n",
      "The previous Error is 0.13545955638434568 and the current error is 0.134010167881437 on iteration 75\n",
      "The previous Error is 0.134010167881437 and the current error is 0.1325811983494522 on iteration 76\n",
      "The previous Error is 0.1325811983494522 and the current error is 0.1311723017839266 on iteration 77\n",
      "The previous Error is 0.1311723017839266 and the current error is 0.12978313423413446 on iteration 78\n",
      "The previous Error is 0.12978313423413446 and the current error is 0.1284133543842062 on iteration 79\n",
      "The previous Error is 0.1284133543842062 and the current error is 0.12706262407525865 on iteration 80\n",
      "The previous Error is 0.12706262407525865 and the current error is 0.12573060877155434 on iteration 81\n",
      "The previous Error is 0.12573060877155434 and the current error is 0.12441697797373955 on iteration 82\n",
      "The previous Error is 0.12441697797373955 and the current error is 0.1231214055822156 on iteration 83\n",
      "The previous Error is 0.1231214055822156 and the current error is 0.12184357021368147 on iteration 84\n",
      "The previous Error is 0.12184357021368147 and the current error is 0.12058315547384585 on iteration 85\n",
      "The previous Error is 0.12058315547384585 and the current error is 0.11933985018925418 on iteration 86\n",
      "The previous Error is 0.11933985018925418 and the current error is 0.11811334860110304 on iteration 87\n",
      "The previous Error is 0.11811334860110304 and the current error is 0.11690335052383297 on iteration 88\n",
      "The previous Error is 0.11690335052383297 and the current error is 0.1157095614711984 on iteration 89\n",
      "The previous Error is 0.1157095614711984 and the current error is 0.11453169275241033 on iteration 90\n",
      "The previous Error is 0.11453169275241033 and the current error is 0.11336946154084318 on iteration 91\n",
      "The previous Error is 0.11336946154084318 and the current error is 0.11222259091768283 on iteration 92\n",
      "The previous Error is 0.11222259091768283 and the current error is 0.11109080989277988 on iteration 93\n",
      "The previous Error is 0.11109080989277988 and the current error is 0.10997385340485513 on iteration 94\n",
      "The previous Error is 0.10997385340485513 and the current error is 0.10887146230308656 on iteration 95\n",
      "The previous Error is 0.10887146230308656 and the current error is 0.10778338331199191 on iteration 96\n",
      "The previous Error is 0.10778338331199191 and the current error is 0.10670936898140349 on iteration 97\n",
      "The previous Error is 0.10670936898140349 and the current error is 0.10564917762322029 on iteration 98\n",
      "The previous Error is 0.10564917762322029 and the current error is 0.10460257323650961 on iteration 99\n",
      "The previous Error is 0.10460257323650961 and the current error is 0.10356932542242475 on iteration 100\n",
      "The previous Error is 0.10356932542242475 and the current error is 0.10254920929029848 on iteration 101\n",
      "The previous Error is 0.10254920929029848 and the current error is 0.1015420053561735 on iteration 102\n",
      "The previous Error is 0.1015420053561735 and the current error is 0.1005474994349337 on iteration 103\n",
      "The previous Error is 0.1005474994349337 and the current error is 0.0995654825271072 on iteration 104\n",
      "The previous Error is 0.0995654825271072 and the current error is 0.09859575070132476 on iteration 105\n",
      "The previous Error is 0.09859575070132476 and the current error is 0.09763810497333461 on iteration 106\n",
      "The previous Error is 0.09763810497333461 and the current error is 0.096692351182393 on iteration 107\n",
      "The previous Error is 0.096692351182393 and the current error is 0.09575829986577686 on iteration 108\n",
      "The previous Error is 0.09575829986577686 and the current error is 0.09483576613209582 on iteration 109\n",
      "The previous Error is 0.09483576613209582 and the current error is 0.09392456953401028 on iteration 110\n",
      "The previous Error is 0.09392456953401028 and the current error is 0.0930245339409058 on iteration 111\n",
      "The previous Error is 0.0930245339409058 and the current error is 0.09213548741201208 on iteration 112\n",
      "The previous Error is 0.09213548741201208 and the current error is 0.09125726207040263 on iteration 113\n",
      "The previous Error is 0.09125726207040263 and the current error is 0.09038969397826085 on iteration 114\n",
      "The previous Error is 0.09038969397826085 and the current error is 0.08953262301375174 on iteration 115\n",
      "The previous Error is 0.08953262301375174 and the current error is 0.08868589274979492 on iteration 116\n",
      "The previous Error is 0.08868589274979492 and the current error is 0.0878493503349958 on iteration 117\n",
      "The previous Error is 0.0878493503349958 and the current error is 0.08702284637695423 on iteration 118\n",
      "The previous Error is 0.08702284637695423 and the current error is 0.08620623482813669 on iteration 119\n",
      "The previous Error is 0.08620623482813669 and the current error is 0.08539937287446793 on iteration 120\n",
      "The previous Error is 0.08539937287446793 and the current error is 0.08460212082676882 on iteration 121\n",
      "The previous Error is 0.08460212082676882 and the current error is 0.08381434201514201 on iteration 122\n",
      "The previous Error is 0.08381434201514201 and the current error is 0.08303590268638404 on iteration 123\n",
      "The previous Error is 0.08303590268638404 and the current error is 0.0822666719044813 on iteration 124\n",
      "The previous Error is 0.0822666719044813 and the current error is 0.08150652145422732 on iteration 125\n",
      "The previous Error is 0.08150652145422732 and the current error is 0.08075532574798369 on iteration 126\n",
      "The previous Error is 0.08075532574798369 and the current error is 0.08001296173558961 on iteration 127\n",
      "The previous Error is 0.08001296173558961 and the current error is 0.07927930881741292 on iteration 128\n",
      "The previous Error is 0.07927930881741292 and the current error is 0.07855424876052224 on iteration 129\n",
      "The previous Error is 0.07855424876052224 and the current error is 0.07783766561794989 on iteration 130\n",
      "The previous Error is 0.07783766561794989 and the current error is 0.07712944565100613 on iteration 131\n",
      "The previous Error is 0.07712944565100613 and the current error is 0.0764294772545949 on iteration 132\n",
      "The previous Error is 0.0764294772545949 and the current error is 0.07573765088547846 on iteration 133\n",
      "The previous Error is 0.07573765088547846 and the current error is 0.07505385899342736 on iteration 134\n",
      "The previous Error is 0.07505385899342736 and the current error is 0.07437799595519051 on iteration 135\n",
      "The previous Error is 0.07437799595519051 and the current error is 0.07370995801121447 on iteration 136\n",
      "The previous Error is 0.07370995801121447 and the current error is 0.07304964320503807 on iteration 137\n",
      "The previous Error is 0.07304964320503807 and the current error is 0.0723969513252847 on iteration 138\n",
      "The previous Error is 0.0723969513252847 and the current error is 0.07175178385017444 on iteration 139\n",
      "The previous Error is 0.07175178385017444 and the current error is 0.07111404389447391 on iteration 140\n",
      "The previous Error is 0.07111404389447391 and the current error is 0.07048363615880343 on iteration 141\n",
      "The previous Error is 0.07048363615880343 and the current error is 0.06986046688121827 on iteration 142\n",
      "The previous Error is 0.06986046688121827 and the current error is 0.06924444379098184 on iteration 143\n",
      "The previous Error is 0.06924444379098184 and the current error is 0.06863547606444861 on iteration 144\n",
      "The previous Error is 0.06863547606444861 and the current error is 0.0680334742829747 on iteration 145\n",
      "The previous Error is 0.0680334742829747 and the current error is 0.06743835039277518 on iteration 146\n",
      "The previous Error is 0.06743835039277518 and the current error is 0.06685001766664826 on iteration 147\n",
      "The previous Error is 0.06685001766664826 and the current error is 0.06626839066748763 on iteration 148\n",
      "The previous Error is 0.06626839066748763 and the current error is 0.06569338521350547 on iteration 149\n",
      "The previous Error is 0.06569338521350547 and the current error is 0.06512491834509096 on iteration 150\n",
      "The previous Error is 0.06512491834509096 and the current error is 0.06456290829323007 on iteration 151\n",
      "The previous Error is 0.06456290829323007 and the current error is 0.06400727444941504 on iteration 152\n",
      "The previous Error is 0.06400727444941504 and the current error is 0.06345793733697283 on iteration 153\n",
      "The previous Error is 0.06345793733697283 and the current error is 0.06291481858374554 on iteration 154\n",
      "The previous Error is 0.06291481858374554 and the current error is 0.062377840896056344 on iteration 155\n",
      "The previous Error is 0.062377840896056344 and the current error is 0.06184692803389697 on iteration 156\n",
      "The previous Error is 0.06184692803389697 and the current error is 0.061322004787275945 on iteration 157\n",
      "The previous Error is 0.061322004787275945 and the current error is 0.06080299695366768 on iteration 158\n",
      "The previous Error is 0.06080299695366768 and the current error is 0.06028983131650514 on iteration 159\n",
      "The previous Error is 0.06028983131650514 and the current error is 0.05978243562466166 on iteration 160\n",
      "The previous Error is 0.05978243562466166 and the current error is 0.05928073857286839 on iteration 161\n",
      "The previous Error is 0.05928073857286839 and the current error is 0.05878466978301736 on iteration 162\n",
      "The previous Error is 0.05878466978301736 and the current error is 0.05829415978630101 on iteration 163\n",
      "The previous Error is 0.05829415978630101 and the current error is 0.057809140006142234 on iteration 164\n",
      "The previous Error is 0.057809140006142234 and the current error is 0.057329542741870285 on iteration 165\n",
      "The previous Error is 0.057329542741870285 and the current error is 0.05685530115310005 on iteration 166\n",
      "The previous Error is 0.05685530115310005 and the current error is 0.05638634924477451 on iteration 167\n",
      "The previous Error is 0.05638634924477451 and the current error is 0.05592262185283163 on iteration 168\n",
      "The previous Error is 0.05592262185283163 and the current error is 0.05546405463045942 on iteration 169\n",
      "The previous Error is 0.05546405463045942 and the current error is 0.055010584034903415 on iteration 170\n",
      "The previous Error is 0.055010584034903415 and the current error is 0.05456214731479457 on iteration 171\n",
      "The previous Error is 0.05456214731479457 and the current error is 0.054118682497965566 on iteration 172\n",
      "The previous Error is 0.054118682497965566 and the current error is 0.05368012837972545 on iteration 173\n",
      "The previous Error is 0.05368012837972545 and the current error is 0.0532464245115654 on iteration 174\n",
      "The previous Error is 0.0532464245115654 and the current error is 0.05281751119026756 on iteration 175\n",
      "The previous Error is 0.05281751119026756 and the current error is 0.0523933294473932 on iteration 176\n",
      "The previous Error is 0.0523933294473932 and the current error is 0.05197382103912516 on iteration 177\n",
      "The previous Error is 0.05197382103912516 and the current error is 0.0515589284364429 on iteration 178\n",
      "The previous Error is 0.0515589284364429 and the current error is 0.05114859481560861 on iteration 179\n",
      "The previous Error is 0.05114859481560861 and the current error is 0.05074276404894454 on iteration 180\n",
      "The previous Error is 0.05074276404894454 and the current error is 0.05034138069588287 on iteration 181\n",
      "The previous Error is 0.05034138069588287 and the current error is 0.049944389994270366 on iteration 182\n",
      "The previous Error is 0.049944389994270366 and the current error is 0.0495517378519114 on iteration 183\n",
      "The previous Error is 0.0495517378519114 and the current error is 0.04916337083833386 on iteration 184\n",
      "The previous Error is 0.04916337083833386 and the current error is 0.048779236176763094 on iteration 185\n",
      "The previous Error is 0.048779236176763094 and the current error is 0.048399281736290864 on iteration 186\n",
      "The previous Error is 0.048399281736290864 and the current error is 0.04802345602422587 on iteration 187\n",
      "The previous Error is 0.04802345602422587 and the current error is 0.04765170817861465 on iteration 188\n",
      "The previous Error is 0.04765170817861465 and the current error is 0.04728398796092134 on iteration 189\n",
      "The previous Error is 0.04728398796092134 and the current error is 0.046920245748855935 on iteration 190\n",
      "The previous Error is 0.046920245748855935 and the current error is 0.046560432529341986 on iteration 191\n",
      "The previous Error is 0.046560432529341986 and the current error is 0.04620449989161389 on iteration 192\n",
      "The previous Error is 0.04620449989161389 and the current error is 0.04585240002043628 on iteration 193\n",
      "The previous Error is 0.04585240002043628 and the current error is 0.04550408568943751 on iteration 194\n",
      "The previous Error is 0.04550408568943751 and the current error is 0.04515951025454985 on iteration 195\n",
      "The previous Error is 0.04515951025454985 and the current error is 0.04481862764755032 on iteration 196\n",
      "The previous Error is 0.04481862764755032 and the current error is 0.04448139236969541 on iteration 197\n",
      "The previous Error is 0.04448139236969541 and the current error is 0.04414775948544483 on iteration 198\n",
      "The previous Error is 0.04414775948544483 and the current error is 0.04381768461626831 on iteration 199\n",
      "The previous Error is 0.04381768461626831 and the current error is 0.04349112393453125 on iteration 200\n",
      "The previous Error is 0.04349112393453125 and the current error is 0.043168034157454904 on iteration 201\n",
      "The previous Error is 0.043168034157454904 and the current error is 0.04284837254114611 on iteration 202\n",
      "The previous Error is 0.04284837254114611 and the current error is 0.04253209687469457 on iteration 203\n",
      "The previous Error is 0.04253209687469457 and the current error is 0.042219165474332576 on iteration 204\n",
      "The previous Error is 0.042219165474332576 and the current error is 0.04190953717765551 on iteration 205\n",
      "The previous Error is 0.04190953717765551 and the current error is 0.041603171337899494 on iteration 206\n",
      "The previous Error is 0.041603171337899494 and the current error is 0.04130002781827402 on iteration 207\n",
      "The previous Error is 0.04130002781827402 and the current error is 0.04100006698634711 on iteration 208\n",
      "The previous Error is 0.04100006698634711 and the current error is 0.04070324970848136 on iteration 209\n",
      "The previous Error is 0.04070324970848136 and the current error is 0.04040953734431859 on iteration 210\n",
      "The previous Error is 0.04040953734431859 and the current error is 0.04011889174131128 on iteration 211\n",
      "The previous Error is 0.04011889174131128 and the current error is 0.039831275229300134 on iteration 212\n",
      "The previous Error is 0.039831275229300134 and the current error is 0.039546650615135626 on iteration 213\n",
      "The previous Error is 0.039546650615135626 and the current error is 0.039264981177342714 on iteration 214\n",
      "The previous Error is 0.039264981177342714 and the current error is 0.03898623066082762 on iteration 215\n",
      "The previous Error is 0.03898623066082762 and the current error is 0.03871036327162616 on iteration 216\n",
      "The previous Error is 0.03871036327162616 and the current error is 0.038437343671691965 on iteration 217\n",
      "The previous Error is 0.038437343671691965 and the current error is 0.038167136973724966 on iteration 218\n",
      "The previous Error is 0.038167136973724966 and the current error is 0.03789970873603864 on iteration 219\n",
      "The previous Error is 0.03789970873603864 and the current error is 0.037635024957466304 on iteration 220\n",
      "The previous Error is 0.037635024957466304 and the current error is 0.037373052072305464 on iteration 221\n",
      "The previous Error is 0.037373052072305464 and the current error is 0.03711375694529999 on iteration 222\n",
      "The previous Error is 0.03711375694529999 and the current error is 0.03685710686666036 on iteration 223\n",
      "The previous Error is 0.03685710686666036 and the current error is 0.03660306954712109 on iteration 224\n",
      "The previous Error is 0.03660306954712109 and the current error is 0.03635161311303538 on iteration 225\n",
      "The previous Error is 0.03635161311303538 and the current error is 0.03610270610150704 on iteration 226\n",
      "The previous Error is 0.03610270610150704 and the current error is 0.03585631745555963 on iteration 227\n",
      "The previous Error is 0.03585631745555963 and the current error is 0.03561241651934248 on iteration 228\n",
      "The previous Error is 0.03561241651934248 and the current error is 0.035370973033373845 on iteration 229\n",
      "The previous Error is 0.035370973033373845 and the current error is 0.03513195712982105 on iteration 230\n",
      "The previous Error is 0.03513195712982105 and the current error is 0.03489533932781806 on iteration 231\n",
      "The previous Error is 0.03489533932781806 and the current error is 0.0346610905288197 on iteration 232\n",
      "The previous Error is 0.0346610905288197 and the current error is 0.034429182011993714 on iteration 233\n",
      "The previous Error is 0.034429182011993714 and the current error is 0.0341995854296497 on iteration 234\n",
      "The previous Error is 0.0341995854296497 and the current error is 0.033972272802705795 on iteration 235\n",
      "The previous Error is 0.033972272802705795 and the current error is 0.03374721651619281 on iteration 236\n",
      "The previous Error is 0.03374721651619281 and the current error is 0.03352438931479616 on iteration 237\n",
      "The previous Error is 0.03352438931479616 and the current error is 0.03330376429843541 on iteration 238\n",
      "The previous Error is 0.03330376429843541 and the current error is 0.03308531491788188 on iteration 239\n",
      "The previous Error is 0.03308531491788188 and the current error is 0.03286901497041422 on iteration 240\n",
      "The previous Error is 0.03286901497041422 and the current error is 0.03265483859551229 on iteration 241\n",
      "The previous Error is 0.03265483859551229 and the current error is 0.03244276027058919 on iteration 242\n",
      "The previous Error is 0.03244276027058919 and the current error is 0.032232754806761583 on iteration 243\n",
      "The previous Error is 0.032232754806761583 and the current error is 0.03202479734465877 on iteration 244\n",
      "The previous Error is 0.03202479734465877 and the current error is 0.03181886335027012 on iteration 245\n",
      "The previous Error is 0.03181886335027012 and the current error is 0.03161492861083125 on iteration 246\n",
      "The previous Error is 0.03161492861083125 and the current error is 0.03141296923074906 on iteration 247\n",
      "The previous Error is 0.03141296923074906 and the current error is 0.031212961627565518 on iteration 248\n",
      "The previous Error is 0.031212961627565518 and the current error is 0.03101488252796019 on iteration 249\n",
      "The previous Error is 0.03101488252796019 and the current error is 0.030818708963792046 on iteration 250\n",
      "The previous Error is 0.030818708963792046 and the current error is 0.03062441826817979 on iteration 251\n",
      "The previous Error is 0.03062441826817979 and the current error is 0.030431988071621778 on iteration 252\n",
      "The previous Error is 0.030431988071621778 and the current error is 0.03024139629815441 on iteration 253\n",
      "The previous Error is 0.03024139629815441 and the current error is 0.030052621161549976 on iteration 254\n",
      "The previous Error is 0.030052621161549976 and the current error is 0.029865641161553207 on iteration 255\n",
      "The previous Error is 0.029865641161553207 and the current error is 0.029680435080157035 on iteration 256\n",
      "The previous Error is 0.029680435080157035 and the current error is 0.029496981977917367 on iteration 257\n",
      "The previous Error is 0.029496981977917367 and the current error is 0.029315261190306745 on iteration 258\n",
      "The previous Error is 0.029315261190306745 and the current error is 0.02913525232410679 on iteration 259\n",
      "The previous Error is 0.02913525232410679 and the current error is 0.02895693525383956 on iteration 260\n",
      "The previous Error is 0.02895693525383956 and the current error is 0.02878029011823787 on iteration 261\n",
      "The previous Error is 0.02878029011823787 and the current error is 0.02860529731675391 on iteration 262\n",
      "The previous Error is 0.02860529731675391 and the current error is 0.028431937506106716 on iteration 263\n",
      "The previous Error is 0.028431937506106716 and the current error is 0.028260191596867948 on iteration 264\n",
      "The previous Error is 0.028260191596867948 and the current error is 0.0280900407500862 on iteration 265\n",
      "The previous Error is 0.0280900407500862 and the current error is 0.027921466373949103 on iteration 266\n",
      "The previous Error is 0.027921466373949103 and the current error is 0.027754450120484296 on iteration 267\n",
      "The previous Error is 0.027754450120484296 and the current error is 0.027588973882297287 on iteration 268\n",
      "The previous Error is 0.027588973882297287 and the current error is 0.027425019789347936 on iteration 269\n",
      "The previous Error is 0.027425019789347936 and the current error is 0.027262570205764232 on iteration 270\n",
      "The previous Error is 0.027262570205764232 and the current error is 0.027101607726693296 on iteration 271\n",
      "The previous Error is 0.027101607726693296 and the current error is 0.02694211517518982 on iteration 272\n",
      "The previous Error is 0.02694211517518982 and the current error is 0.026784075599141782 on iteration 273\n",
      "The previous Error is 0.026784075599141782 and the current error is 0.026627472268232318 on iteration 274\n",
      "The previous Error is 0.026627472268232318 and the current error is 0.026472288670938926 on iteration 275\n",
      "The previous Error is 0.026472288670938926 and the current error is 0.026318508511568653 on iteration 276\n",
      "The previous Error is 0.026318508511568653 and the current error is 0.026166115707329542 on iteration 277\n",
      "The previous Error is 0.026166115707329542 and the current error is 0.026015094385438187 on iteration 278\n",
      "The previous Error is 0.026015094385438187 and the current error is 0.0258654288802627 on iteration 279\n",
      "The previous Error is 0.0258654288802627 and the current error is 0.025717103730501373 on iteration 280\n",
      "The previous Error is 0.025717103730501373 and the current error is 0.025570103676396526 on iteration 281\n",
      "The previous Error is 0.025570103676396526 and the current error is 0.025424413656983003 on iteration 282\n",
      "The previous Error is 0.025424413656983003 and the current error is 0.02528001880737195 on iteration 283\n",
      "The previous Error is 0.02528001880737195 and the current error is 0.025136904456068324 on iteration 284\n",
      "The previous Error is 0.025136904456068324 and the current error is 0.024995056122323035 on iteration 285\n",
      "The previous Error is 0.024995056122323035 and the current error is 0.024854459513518813 on iteration 286\n",
      "The previous Error is 0.024854459513518813 and the current error is 0.024715100522589517 on iteration 287\n",
      "The previous Error is 0.024715100522589517 and the current error is 0.024576965225473018 on iteration 288\n",
      "The previous Error is 0.024576965225473018 and the current error is 0.024440039878596845 on iteration 289\n",
      "The previous Error is 0.024440039878596845 and the current error is 0.024304310916396656 on iteration 290\n",
      "The previous Error is 0.024304310916396656 and the current error is 0.02416976494886728 on iteration 291\n",
      "The previous Error is 0.02416976494886728 and the current error is 0.0240363887591455 on iteration 292\n",
      "The previous Error is 0.0240363887591455 and the current error is 0.023904169301125044 on iteration 293\n",
      "The previous Error is 0.023904169301125044 and the current error is 0.023773093697103023 on iteration 294\n",
      "The previous Error is 0.023773093697103023 and the current error is 0.023643149235457427 on iteration 295\n",
      "The previous Error is 0.023643149235457427 and the current error is 0.023514323368355634 on iteration 296\n",
      "The previous Error is 0.023514323368355634 and the current error is 0.02338660370949366 on iteration 297\n",
      "The previous Error is 0.02338660370949366 and the current error is 0.023259978031865393 on iteration 298\n",
      "The previous Error is 0.023259978031865393 and the current error is 0.023134434265562137 on iteration 299\n",
      "The previous Error is 0.023134434265562137 and the current error is 0.023009960495601743 on iteration 300\n",
      "The previous Error is 0.023009960495601743 and the current error is 0.022886544959786783 on iteration 301\n",
      "The previous Error is 0.022886544959786783 and the current error is 0.022764176046592387 on iteration 302\n",
      "The previous Error is 0.022764176046592387 and the current error is 0.02264284229308223 on iteration 303\n",
      "The previous Error is 0.02264284229308223 and the current error is 0.022522532382853403 on iteration 304\n",
      "The previous Error is 0.022522532382853403 and the current error is 0.02240323514400893 on iteration 305\n",
      "The previous Error is 0.02240323514400893 and the current error is 0.022284939547158558 on iteration 306\n",
      "The previous Error is 0.022284939547158558 and the current error is 0.02216763470344665 on iteration 307\n",
      "The previous Error is 0.02216763470344665 and the current error is 0.022051309862607532 on iteration 308\n",
      "The previous Error is 0.022051309862607532 and the current error is 0.02193595441104748 on iteration 309\n",
      "The previous Error is 0.02193595441104748 and the current error is 0.021821557869953434 on iteration 310\n",
      "The previous Error is 0.021821557869953434 and the current error is 0.021708109893427745 on iteration 311\n",
      "The previous Error is 0.021708109893427745 and the current error is 0.021595600266649022 on iteration 312\n",
      "The previous Error is 0.021595600266649022 and the current error is 0.021484018904058662 on iteration 313\n",
      "The previous Error is 0.021484018904058662 and the current error is 0.02137335584757237 on iteration 314\n",
      "The previous Error is 0.02137335584757237 and the current error is 0.02126360126481698 on iteration 315\n",
      "The previous Error is 0.02126360126481698 and the current error is 0.021154745447391946 on iteration 316\n",
      "The previous Error is 0.021154745447391946 and the current error is 0.02104677880915501 on iteration 317\n",
      "The previous Error is 0.02104677880915501 and the current error is 0.020939691884532166 on iteration 318\n",
      "The previous Error is 0.020939691884532166 and the current error is 0.020833475326851543 on iteration 319\n",
      "The previous Error is 0.020833475326851543 and the current error is 0.020728119906700343 on iteration 320\n",
      "The previous Error is 0.020728119906700343 and the current error is 0.02062361651030549 on iteration 321\n",
      "The previous Error is 0.02062361651030549 and the current error is 0.020519956137936623 on iteration 322\n",
      "The previous Error is 0.020519956137936623 and the current error is 0.02041712990233243 on iteration 323\n",
      "The previous Error is 0.02041712990233243 and the current error is 0.020315129027148545 on iteration 324\n",
      "The previous Error is 0.020315129027148545 and the current error is 0.020213944845427944 on iteration 325\n",
      "The previous Error is 0.020213944845427944 and the current error is 0.02011356879809308 on iteration 326\n",
      "The Weights and Biases after running the neural network for the activation function sigmoid are as follows:\n",
      "Weights are[0.16813417830185814, 0.23626835660371678, 0.267643161092456, 0.33528632218491244, -0.9616369109448438, -0.9189995324975873, 1.3232947078754467, 1.3775243357607434]\n",
      "Biases are [1.0655467878862903, -0.2853535200035471]\n"
     ]
    }
   ],
   "source": [
    "NeuralNetworkSigmoid(x1,x2,w1,w2,w3,w4,b1,w5,w6,w7,w8,b2,o1,o2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weights are [array([[-1.18860888,  0.01231954],\n",
      "       [-0.51833071,  0.50263447]]), array([[ 0.12314487, -0.15756002],\n",
      "       [-0.74208451,  0.49010117]])]\n",
      "The biases are [array([-0.31483903, -0.24381801]), array([0.25186832, 0.78131105])]\n"
     ]
    }
   ],
   "source": [
    "print(\"The weights are \"+str(nn.coefs_))\n",
    "print(\"The biases are \"+str(nn.intercepts_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.32220237\n",
      "Iteration 2, loss = 0.20731920\n",
      "Iteration 3, loss = 0.12378156\n",
      "Iteration 4, loss = 0.06383038\n",
      "Iteration 5, loss = 0.02177153\n",
      "Iteration 6, loss = 0.00211640\n",
      "Iteration 7, loss = 0.00652930\n",
      "Iteration 8, loss = 0.02739096\n",
      "Iteration 9, loss = 0.04892239\n",
      "Iteration 10, loss = 0.05890855\n",
      "Iteration 11, loss = 0.05585901\n",
      "Iteration 12, loss = 0.04465802\n",
      "Iteration 13, loss = 0.03095000\n",
      "Iteration 14, loss = 0.01843102\n",
      "Iteration 15, loss = 0.00880408\n",
      "Iteration 16, loss = 0.00283415\n",
      "Iteration 17, loss = 0.00079295\n",
      "Iteration 18, loss = 0.00226789\n",
      "Iteration 19, loss = 0.00607594\n",
      "Iteration 20, loss = 0.01055505\n",
      "Iteration 21, loss = 0.01410993\n",
      "Iteration 22, loss = 0.01572960\n",
      "Iteration 23, loss = 0.01520748\n",
      "Iteration 24, loss = 0.01300400\n",
      "Iteration 25, loss = 0.00990440\n",
      "Iteration 26, loss = 0.00667415\n",
      "Iteration 27, loss = 0.00385758\n",
      "Iteration 28, loss = 0.00176343\n",
      "Training loss did not improve more than tol=0.001000 for 10 consecutive epochs. Stopping.\n",
      "The weights are [array([[-0.13326943,  0.61055745],\n",
      "       [ 0.07565849,  0.1768912 ]]), array([[-0.51716333,  1.02283353],\n",
      "       [ 0.67118976,  0.68415426]])]\n",
      "The biases are [array([-0.2228719 , -0.39512765]), array([0.0020227 , 0.22682914])]\n"
     ]
    }
   ],
   "source": [
    "nn=MLPRegressor(hidden_layer_sizes=2,activation='logistic',tol=0.001,verbose=10,learning_rate_init=0.1,alpha=0)\n",
    "X=[[x1,x2]]\n",
    "y=[[o1,o2]]\n",
    "nn.fit(X,y)\n",
    "print(\"The weights are \"+str(nn.coefs_))\n",
    "print(\"The biases are \"+str(nn.intercepts_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The previous Error is inf and the current error is 0.4211247656249999 on iteration 1\n",
      "The previous Error is 0.4211247656249999 and the current error is 0.2942144938106399 on iteration 2\n",
      "The previous Error is 0.2942144938106399 and the current error is 0.24019143027548653 on iteration 3\n",
      "The previous Error is 0.24019143027548653 and the current error is 0.21361494798382366 on iteration 4\n",
      "The previous Error is 0.21361494798382366 and the current error is 0.19781741561755842 on iteration 5\n",
      "The previous Error is 0.19781741561755842 and the current error is 0.18616285825033274 on iteration 6\n",
      "The previous Error is 0.18616285825033274 and the current error is 0.17588694516933095 on iteration 7\n",
      "The previous Error is 0.17588694516933095 and the current error is 0.165816962408341 on iteration 8\n",
      "The previous Error is 0.165816962408341 and the current error is 0.155469575195414 on iteration 9\n",
      "The previous Error is 0.155469575195414 and the current error is 0.14467979081821503 on iteration 10\n",
      "The previous Error is 0.14467979081821503 and the current error is 0.1334442067612167 on iteration 11\n",
      "The previous Error is 0.1334442067612167 and the current error is 0.12185205786882902 on iteration 12\n",
      "The previous Error is 0.12185205786882902 and the current error is 0.11005144036445771 on iteration 13\n",
      "The previous Error is 0.11005144036445771 and the current error is 0.09822837146076649 on iteration 14\n",
      "The previous Error is 0.09822837146076649 and the current error is 0.0865894508976706 on iteration 15\n",
      "The previous Error is 0.0865894508976706 and the current error is 0.07534496295009749 on iteration 16\n",
      "The previous Error is 0.07534496295009749 and the current error is 0.0646922584657588 on iteration 17\n",
      "The previous Error is 0.0646922584657588 and the current error is 0.05480069703017756 on iteration 18\n",
      "The previous Error is 0.05480069703017756 and the current error is 0.045799870224439536 on iteration 19\n",
      "The previous Error is 0.045799870224439536 and the current error is 0.03777253570371366 on iteration 20\n",
      "The previous Error is 0.03777253570371366 and the current error is 0.030752919639122918 on iteration 21\n",
      "The previous Error is 0.030752919639122918 and the current error is 0.024730094125298058 on iteration 22\n",
      "The previous Error is 0.024730094125298058 and the current error is 0.019655309432002964 on iteration 23\n",
      "The previous Error is 0.019655309432002964 and the current error is 0.01545167487993239 on iteration 24\n",
      "The previous Error is 0.01545167487993239 and the current error is 0.012024509285845095 on iteration 25\n",
      "The previous Error is 0.012024509285845095 and the current error is 0.00927095586085314 on iteration 26\n",
      "The previous Error is 0.00927095586085314 and the current error is 0.007087927435079458 on iteration 27\n",
      "The previous Error is 0.007087927435079458 and the current error is 0.005377954501246031 on iteration 28\n",
      "The previous Error is 0.005377954501246031 and the current error is 0.004052931106510114 on iteration 29\n",
      "The previous Error is 0.004052931106510114 and the current error is 0.003036034611163328 on iteration 30\n",
      "The Weights and Biases after running the neural network for the activation function sigmoid are as follows:\n",
      "Weights are[0.1560169603188127, 0.21203392063762544, 0.2554979926336867, 0.3109959852673733, -0.002575082106884297, 0.03166181099117372, 0.6978672192181399, 0.7556377266315285]\n",
      "Biases are [0.5802990590499884, 0.06412902856080185]\n"
     ]
    }
   ],
   "source": [
    "NeuralNetworkRelu(x1,x2,w1,w2,w3,w4,b1,w5,w6,w7,w8,b2,o1,o2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weights are [array([[ 0.40547296,  0.08776169],\n",
      "       [ 1.41923113, -0.09519379]]), array([[-0.56882565,  0.96087425],\n",
      "       [-0.00536622,  0.01382439]])]\n",
      "The biases are [array([ 0.76361954, -1.03147225]), array([0.46793339, 0.05352433])]\n"
     ]
    }
   ],
   "source": [
    "nn=MLPRegressor(hidden_layer_sizes=2,activation='relu',tol=0.001,learning_rate_init=0.1)\n",
    "X=[[x1,x2]]\n",
    "y=[[o1,o2]]\n",
    "nn.fit(X,y)\n",
    "print(\"The weights are \"+str(nn.coefs_))\n",
    "print(\"The biases are \"+str(nn.intercepts_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.07635226, -0.0180516 ],\n",
       "        [-0.18616757,  0.3840937 ]]), array([[0.1786076 , 0.71563225],\n",
       "        [0.36950813, 1.12441971]])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
